\documentclass[runningheads,a4paper,11pt]{article}

\usepackage{algorithmic}
\usepackage{algorithm} 
\usepackage{array}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{cite}
\usepackage{comment} 
\usepackage{enumitem}
\usepackage{epsfig} 
\usepackage{fancyhdr}
\usepackage[T1]{fontenc}
\usepackage{geometry} 
\usepackage{graphicx}
\usepackage[colorlinks]{hyperref} 
\usepackage[latin1]{inputenc}
\usepackage{interval}
\usepackage{multicol}
\usepackage{multirow} 
\usepackage{rotating}
\usepackage{setspace}
\usepackage{subfigure}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{url}
\usepackage{verbatim}
\usepackage{xcolor}
\usepackage{xstring}

\geometry{a4paper,top=2.5cm,left=2cm,right=2cm,bottom=2cm}


\begin{document}
\title{How Consistent are LLMs in Applying Handcrafted Language Features}
\author{Andrei Olar --- andrei.olar@ubbcluj.ro}
\maketitle
\begin{abstract}
    Large language models are sought for solving an increasing number of
    increasingly diverse tasks. Perhaps naturally one such task is text style
    transfer: the task of changing the style of a text while preserving its
    meaning. Besides the natural approach of fine-tuning a large language model,
    a simpler and cheaper alternative should also be investigated: using
    handcrafted language features to direct the large language model.
\end{abstract}

\section{Introduction}\label{introduction}

\textbf{Large language models (LLMs)} have are now a commonplace research topic.
Because language models such as BERT~\cite{devlin2018bert} or GPT~\cite{gpt-2018,gpt2-2019,
gpt3-2020} constantly advance the state of the art for many natural language
processing tasks, it has become natural to want to evaluate these models
performance on ever more tasks.
We know from multiple surveys~\cite{minaee2024llmsurvey,zhao2023survey} and
benchmarks~\cite{papcode2024hellaswag,chiang2024chatbot} that large language
models (especially the more popular ones) are very good at following
instructions.
We can also intuit that training LLMs on diverse data (for instance the
Pile~\cite{gao2020pile}) uniquely qualifies them to produce text in a wide
variety of styles.

\textbf{Text style transfer (TST)} is defined as the ``task of transforming the
stylistic manner in which a sentence is written, while preserving the meaning of
the original sentence''~\cite{tst-review-2021}.
This definition can be extended, to entire articles or corpuses containing
multiple articles without fear of text style transfer losing its meaning.
The task of transfering text style is an old preocupation for the natural
language processing and computational linguistics communities which has picked
up interest again in the context of the advancements in the field of deep
learning and particularly since the inception of the transformer architecture.

\textbf{Handcrafted linguistic features (HLFs)} are single numerical values produced by a
uniquely identifiable method on any natural language~\cite{lftk-2023}. More
often than not, these features are easy to compute and intuitively very telling
of the style in which a text is written.

Let's take the number of exclamations in a text as an example.
This particular HLF is one of the easier computational linguistics features to
compute.
Yet high values of this particular HLF often provide a clear signal for
inflamatory news writing style, spam or an alert narrative.
Similar observations have been made about other characteristics of written text
that might be computed as HLFs~\cite{hovy1987generating}.
This gives rise to the hope that text style can be sufficiently, although not
completely, described through the use of HLFs.
What's most appealing about HLFs is their idempotent nature.
They could potentially be used both for interpreting style and generating text
with a given style.

From the above ideas, a couple of questions arise naturally.
Firstly, is it possible to influence an LLMs writing style by instructing it to
generate text in accordance to certain HLFs?
This problem of controlled text generation has implications for text style
transfer and authorship evaluation.
It might also constitute a cheaper and less intrusive approach than fine tuning
an LLM.
Fine tuning an LLM incurs some loss of generality~\cite{yang2024unveiling}.

Secondly, we ask if it's possible to tell just how well the most prominent LLMs
of today are able to generate text according to instructions concerning HLFs?
The answer to this question could hint at a relatively simple and accurate way
of at least partially evaluating LLM performance on the text style transfer
task.

\section{Related Work}\label{related}

There is abundent literature on the topic of text style transfer.
Reviews and surveys~\cite{tst-review-2021,tst-survey-2022} were helpful for
informing our selection of HLFs.
Studies on attaining fine-grained text style transfer using language models
have served as inspiration for writing this paper~\cite{lyu-etal-2023-fine}.
We should note though that we are not attempting to transfer text style, but
merely to instruct an LLM to follow instructions based on HLFs.

From a linguistic perspective, text style can be thought of as the form used for
delivering meaning~\cite{tst_sigkdd_review_2022}.
The ample literature on the subject seems to agree that style depends on context
and author choice vis-a-vis a communication
goal~\cite{mcdonald1985computational,hovy1987generating}.
The author's choice is available at all levels: lexical, syntactic and
semantic~\cite{dimarco1994model}.
These findings provide the hope and evidence that the current paper is useful
especially when it comes to the influence of syntactic structure over text
style~\cite{chomsky2002syntactic}.

The idea of constructing style from fine-grained aspects is not new and there
are excellent studies on the subject. The StylePTB authors (StylePTB is one of
the benchmark datasets used in this paper) explain how this dataset leverages
lexical, syntactic, semantic and thematic aspects to allow verifying text style
transfer more thoroughly than previous methods~\cite{lyu-etal-2021-styleptb}.
In the current paper we use this dataset merely to instruct LLMs to rewrite text
from it, without actually measuring style transfer quality.

The body of work on HLFs is extensive.
It is well referenced and synthesised by Lee and Lee~\cite{lftk-2023}.
To our knowledge there is no work that connects HLFs with LLMs in the manner
described in this paper.
Most other literature focuses on achieving results on connected tasks, such as
assessing text readability~\cite{lee-etal-2021-pushing}.
This paper differs from other tasks that aim to control the style of generated
text in at least two significant ways.
Firstly, this paper is simply about feeding well crafted user prompts to an LLM
instead of diving into deeper concepts such as the transformer architecture,
deep learning or even neural networks.
Secondly, it focuses on manipulating the style attributes of the text generated
by an LLM squarely using HLFs and measuring the change in output.
There is no ulterior motive.

Finally, this paper documents a form of controllable text generation (CTG)~\cite{zhang-ctg-2022}.
Hightened recent interest in CTG and especially in benchmarking LLMs in the
context of CTG~\cite{chen2024benchmarking} is particularly relevant for this
paper.
Such research alleviates the burden of proof regarding the level to which
LLMs respond well to diversified instructions for controlled text generation in
general.
The novelty of this paper lies both in basing the control instructions on
HLFs and in using those HLFs to evaluate the performance of the LLM.

\section{Experiment Design}\label{method}

Our experiment consists of analysing the behavior of an LLM when asked to
generate new text based on a given text and and instructions derived from HLF
statistics computed on a benchmark dataset.
To perform the experiment we must know which LLMs we are going to evaluate and
what benchmark datasets we are going to use.
We must also select the HLFs for our experiment.

Before answering those questions, let us outline the experimental process.

The first task in the experiment is to establish a baseline.
We do so by instructing the target LLM to generate text retaining the meaning of
the input text without any further instruction.
We repeat the text generation step 10 times.
For each text generation, we compute the following statistics for each of our
chosen HLFs:

\begin{itemize}
    \item \textbf{min}: the minimum value of the HLF on the generated text;
    \item \textbf{max}: the maximum value of the HLF on the generated text;
    \item \textbf{avg}: the mean value of the HLF on the generated text;
    \item \textbf{var}: the variance of the HLF values on the generated text.
\end{itemize}

A second baseline is obtained by following the above process with a new prompt
that builds upon the first one by adding the instruction to use example
text from our benchmark dataset of choice.
The examples are five texts chosen randomly once for each benchmark dataset.
These example texts are the same for all evaluated LLMs.

The next step is to devise HLF prompts derived from both baseline prompts.
The HLF prompts contain additional instructions to generate text that would
comply with certain HLF values.
These HLF values are obtained by computing the statistics outlined above on
the entirety of the target benchmark dataset.
We then repeat the process through which we created the baselines for each of
the HLF prompts.

To answer our first question, we compare the first baseline with the results
obtained by using the corresponding modified HLF prompt.
Our reasoning is that if the LLM were influenced by the HLF prompt, the output
would show different HLF values compared to the baseline.

To answer the question of how much LLMs are influenced by being prompted with
instructions about HLFs, we turn our attention to the second baseline.
Given that the LLM now also has example articles, it can freely immitate those
articles when generating the text.
If there is a consistent difference between the HLF and non-HLF prompt, this
difference can only stem from the HLF instructions.
We perform this second experiment with input text from both within and outside
the corpus.

One final observation before diving into details is that we can use an HLF's
variance on the benchmark dataset to our advantage.
This statistic shows whether the LLM takes the HLF prompts into account enough
for the generated text to fall within the parameters of the benchmark dataset.
Let us denote an HLF computed on a generated text using an HLF prompt with
$HLF_g$.
Similarly denote the average and the variance of the same HLF on the benchmark
dataset with $avg(HLF_b)$ and $var(HLF_b)$, respectively.
If we consistently notice that
    \[HLF_g - var(HLF_b) \leq avg(HLF_b) \leq HLF_g + var(HLF_b)\]
then we consider that the LLM follows HLF prompts in a relevant way.

\subsection{LLM Selection}\label{llm-selection}

In order to perform our experiment we must first choose proper candidates.
Since the interaction with the model happens only via prompts, we may use models
with any type of licensing.
For our experiment we choose the top model from each of the highest scoring five
different major vendors listed on the Chatbot Arena~\cite{chiang2024chatbot}
leaderboard.
The final choice is documented in Table~\ref{table-llm}.

\begin{table}[ht]
    \setlength\tabcolsep{6pt}
    \centering
\begin{tabular}{@{}lllll@{}}\toprule
Name                      & Parameters           & Context Size        & Elo Score & License Type                                      \\ \toprule
OpenAI GPT-4o             & undisclosed          & 128000              & 1287      & Proprietary                                       \\
Google Gemini 1.5 Pro     & undisclosed          & 1048576             & 1268      & Proprietary                                       \\
Anthropic Claude 3 Opus   & undisclosed          & 200000              & 1248      & Proprietary                                       \\
Meta Llama 3-70B-Instruct & 70 Billion           & 8000                & 1208      & Llama 3 Community                                 \\
Cohere Command R+         & 104 Billion          & 128000              & 1189      & CC-BY-NC 4.0 \\
                          &                      &                     &           & with Acceptable Use\\
                          &                      &                     &           & Addendum\\ \bottomrule
\end{tabular}
\caption{Experiment LLMs}\label{table-llm}
\end{table}

\subsection{HLF Selection}\label{hlf-selection}

On the other hand, we need to look at which handcrafted linguistic features are
relevant for our experiment.
In our opinion, good handcrafted linguistic features for the task of text style
transfer are those features that can reasonably be thought to affect one of the
coordinates by which people judge the style of text.
These coordinates are well enumerated both in~\cite{tst-review-2021} and
in~\cite{tst-survey-2022}.

In order to build upon the previous work done regarding computing handcrafted
linguistic features, we will rely only on the features available in
LFTK~\cite{lftk-2023}.

Based on the above two selection criteria, we have selected the handcrafted
linguistic features in <INSERT TABLE HERE>.

\subsection{DataSet Selection}\label{ds-selection}

- Are there benchmark datasets for text style transfer? (STYLEPTB + Yelp Reviews)

\subsection{Input Prompt and Text}\label{input-text}

- link to text from within the corpus
- link to text from outside the corpus
- link to each system prompt (2 baselines, 2 HLF prompt templates)

\section{Experiment Results}

\subsection{Graph Interpretation}

Ox - the number of the generation 1..10
Oy - HLF value
Continuous grey line - baseline metric
continuous grenat line - hlf metric
grey around grenat line - corpus target zone
dotted black lines - corpus min, max
continuous black line - corpus avg

\subsection{Baseline}

Yelp Results

STYLEPTB Results

\subsection{Context Aware}

Yelp Results
StylePTB Results

\section{Discussion}

Discuss experiment results here.

\section{Conclusions and Future Work}

Yes, you can instruct at least some of the LLMs with HLFs.

compute BLEU, meteor, cider on styleptb using these LLMs and the prompt to
evaluate whether we actually achieve style transfer because of/in spite of HLF
instructions.
Human survey (amazon mechanical turk) on whether the text generations are good
or not. Likert scale (0 no good, 10 matches style perfectly)

\bibliographystyle{plain}
\bibliography{references}
\end{document}